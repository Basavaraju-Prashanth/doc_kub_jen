========== Steps to install the swarm cluster ========

Create a 3 cluster node where we will have one node a manager / leader / master and other nodes as workers

In hosts file add other nodes details to keep them all communicated.

On Manager Node run the command to initiate the manager on the swarm cluster,
#docker swarm init --> This will create a manager node and it will provide a token which will be used to run on the worker node to join the cluster

If there are multiple eth cards , then we need to specify the IP with with node will be created a manager,
#docker swarm init --advertise-addr 192.168.99.12

Port is optional while specifying the IP but make sure the port with which the manager node is configured must be enable at the firewall level,
#firewall-cmd --add-port=2377/tcp --permanent
#firewall-cmd --reload

1. ca - option to view the certificate
#docker swarm ca

2. init - initiate a swarm with single node swarm cluster on the node which will be manager
#docker swarm init 
or
#docker swarm init --advertise-addr IP

3. join - Join the swarm as a node or manager
#docker swarm join --token SWMTKN-1-14nel7timmws0akhy54tgsfwk9fuploopaywon0kv4zh38la13-7gr871cj6wfklx5oqgq0cmq7r 192.168.1.102:2377
This node joined a swarm as a worker

Above command was retrived while the manager node was created and the same was copied and ran in the worker node to join the cluster.

4. join-token - This provides the token required to join either a node or another manager which can be copied to node to make the desired and should be run in manager node
[root@master ~]# docker swarm join-token worker
To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-14nel7timmws0akhy54tgsfwk9fuploopaywon0kv4zh38la13-7gr871cj6wfklx5oqgq0cmq7r 192.168.1.102:2377

[root@master ~]# docker swarm join-token manager
To add a manager to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-14nel7timmws0akhy54tgsfwk9fuploopaywon0kv4zh38la13-7tawo694kd860s4c5866qeh7u 192.168.1.102:2377

If we are making multiple manager node then make sure the port are open and add it permanent

#firewall-cmd --add-port=2377/tcp --permanent
#firewall-cmd --reload

Then run the manager token,
docker swarm join --token SWMTKN-1-14nel7timmws0akhy54tgsfwk9fuploopaywon0kv4zh38la13-7tawo694kd860s4c5866qeh7u 192.168.1.102:2377

5. leave - leave the swarm cluster, make sure there are quorum of managers available if we are going to leave the manager else we will removed from the cluster and will not be able to view the cluser details

the below error will be printed
[root@master ~]# docker node ls
Error response from daemon: rpc error: code = Unknown desc = The swarm does not have a leader. It's possible that too few managers are online. Make sure more than half of the managers are online.

The above issue happens,

[root@worker-node2 ~]# docker swarm leave
Error response from daemon: You are attempting to leave the swarm on a node that is participating as a manager. Removing this node leaves 1 managers out of 2. Without a Raft quorum your swarm will be inaccessible. The only way to restore a swarm that has lost consensus is to reinitialize it with `--force-new-cluster`. Use `--force` to suppress this message.
[root@worker-node2 ~]# docker swarm leave --force
Node left the swarm.


When this command is executed in removing a manager node

To Fix this issue we need to force the cluster

[root@master ~]# docker swarm init --force-new-cluster
Swarm initialized: current node (qm52lcl4lkrhupql58813mkyl) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-14nel7timmws0akhy54tgsfwk9fuploopaywon0kv4zh38la13-7gr871cj6wfklx5oqgq0cmq7r 192.168.1.102:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.


After which the cluster will be back with one manager node and one worker node

[root@master ~]# docker node ls
ID                            HOSTNAME       STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
wje99d488y9n3bjx0sngbayrc                    Down      Active
qm52lcl4lkrhupql58813mkyl *   master         Ready     Active         Leader           20.10.12
3kn4x5o9p3u8w9oct8q8mxsdp     worker-node1   Ready     Active                          20.10.13
i6u3utfshn0ntu9gpbxuph662     worker-node2   Down      Active                          20.10.13


The node which leave swarm cluster details will be still visible in the node list but it will be in down state

We can remove the node down using command,
#docker node rm ID

===================== Node Commands =================

1. demote - Demote one or more nodes from manager in the swarm
Run this from the manager node,

#docker node demote node-1 node2 -- node specifys the hostname

2. inspect - Display detailed information of nodes
#docker node inspect wj

3. ls - Display all nodes in the swarm
#docker node ls

4. promote - Promote nodes as manager and needs to be run from manager node,
#docker node promote worker-node1

5. ps - Lists all tasks running on one or more node
#docker node ps

[root@master ~]# docker node ps
ID             NAME          IMAGE          NODE      DESIRED STATE   CURRENT STATE            ERROR                              PORTS
qewlsmhy9kip   nginx.1       nginx:latest   master    Running         Running 20 minutes ago
iw0t18ecsv6i    \_ nginx.1   nginx:latest   master    Shutdown        Failed 20 minutes ago    "No such container: nginx.1.iwâ€¦"


6. rm - remove a node from swarm and will not be removed if it is in running state
#docker node rm id/name

7. update - Update a node
Example
#docker node update --label-add foo worker1  -- where we specify the label with key and no value

========================================== Service  Commands ============================================

1. create -- Create a service 

a. #docker service create --name nginx -p 5000:80 nginx 

The service will be created only on the manager node,

Below command will be creating service with 3 containers replicated on all 3 nodes


b. [root@master ~]# docker service create --name nginx --replicas 3 -p 5000:80 nginx
w9f895z5731be0pfs4exdu11t
overall progress: 3 out of 3 tasks
1/3: running   [==================================================>]
2/3: running   [==================================================>]
3/3: running   [==================================================>]
verify: Service converged
[root@master ~]# docker node ls
ID                            HOSTNAME       STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
qm52lcl4lkrhupql58813mkyl *   master         Ready     Active         Leader           20.10.12
ke6dbt5rw4nb114g4gwbegmua     worker-node1   Ready     Active                          20.10.13
cv9z7sfi071tet6dtbb8igpvc     worker-node2   Ready     Active                          20.10.13
[root@master ~]# docker service ps nginx
ID             NAME      IMAGE          NODE           DESIRED STATE   CURRENT STATE                ERROR     PORTS
889wtun98wa6   nginx.1   nginx:latest   worker-node1   Running         Running about a minute ago
g8llwbwav2nr   nginx.2   nginx:latest   master         Running         Running 2 minutes ago
svpymphvdtqa   nginx.3   nginx:latest   worker-node2   Running         Running 59 seconds ago


c. [root@master ~]# docker service create --name nginx --replicas 4 -p 5000:80 nginx
po4yyroaab11zbi2eyv0ynxg7
overall progress: 4 out of 4 tasks
1/4: running   [==================================================>]
2/4: running   [==================================================>]
3/4: running   [==================================================>]
4/4: running   [==================================================>]
verify: Service converged
[root@master ~]# docker service ls
ID             NAME      MODE         REPLICAS   IMAGE          PORTS
po4yyroaab11   nginx     replicated   4/4        nginx:latest   *:5000->80/tcp
[root@master ~]# docker service ps nginx
ID             NAME      IMAGE          NODE           DESIRED STATE   CURRENT STATE            ERROR     PORTS
1t9u30h2f2h5   nginx.1   nginx:latest   worker-node2   Running         Running 8 seconds ago
p4hmeyt5zn2b   nginx.2   nginx:latest   worker-node1   Running         Running 25 seconds ago
zfsub2ejs2wb   nginx.3   nginx:latest   master         Running         Running 26 seconds ago
w12om1twc8el   nginx.4   nginx:latest   worker-node2   Running         Running 8 seconds ago

Here we have replicated the service with value 4 hence in one node we will have 2 containers running, in the above example we can see worker-node2 has multiple continers runnings.

2. ls - To list all services running
#docker service ls

3. logs - Fetch the logs of service
#docker service logs servicename/task

4. ps - List tasks of the service
#docker service ps nginx

5. rollback - Reverts changes to old service configuration,

[root@master ~]# docker service create --name my-service -p 8080:80 nginx:alpine
o3fdvcoev75jq7frf4gtjsn0u
overall progress: 1 out of 1 tasks
1/1: running   [==================================================>]
verify: Service converged
[root@master ~]# docker service ls
ID             NAME         MODE         REPLICAS   IMAGE          PORTS
o3fdvcoev75j   my-service   replicated   1/1        nginx:alpine   *:8080->80/tcp
[root@master ~]# docker service ps o3
ID             NAME           IMAGE          NODE      DESIRED STATE   CURRENT STATE            ERROR     PORTS
odlsgvwu777j   my-service.1   nginx:alpine   master    Running         Running 19 seconds ago
[root@master ~]# docker service update --replicas=3 my-service
my-service
overall progress: 3 out of 3 tasks
1/3: running   [==================================================>]
2/3: running   [==================================================>]
3/3: running   [==================================================>]
verify: Service converged
[root@master ~]# docker service ls
ID             NAME         MODE         REPLICAS   IMAGE          PORTS
o3fdvcoev75j   my-service   replicated   3/3        nginx:alpine   *:8080->80/tcp
[root@master ~]# docker service ps my-service
ID             NAME           IMAGE          NODE           DESIRED STATE   CURRENT STATE                ERROR     PORTS
odlsgvwu777j   my-service.1   nginx:alpine   master         Running         Running about a minute ago
wjdyn84xkimw   my-service.2   nginx:alpine   worker-node2   Running         Running 8 seconds ago
xf5r9ybw7p41   my-service.3   nginx:alpine   worker-node1   Running         Running 24 seconds ago
[root@master ~]# docker service rollback my-service
my-service
overall progress: rolling back update: 1 out of 1 tasks
1/1: running   [>                                                  ]
verify: Service converged
rollback: rollback completed
[root@master ~]# docker service ls
ID             NAME         MODE         REPLICAS   IMAGE          PORTS
o3fdvcoev75j   my-service   replicated   1/1        nginx:alpine   *:8080->80/tcp

6. rm - Remove one or more services
#docker service rm my-service

 


